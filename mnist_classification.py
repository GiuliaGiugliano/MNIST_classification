# -*- coding: utf-8 -*-
"""MNIST_CLASSIFICATION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NltQUA4zH5Pop3Qkmie0HA2rnclm2In3

This projects aims to classify the MNIST dataset by using different machine learning models: RidgeClassifier, LogisticRegression, DecisionTree, RandomForest, Support Vector Machine (SVM) and by implementing a Convolutional Neural Network (CNN). The models are trained on a training set and verified on a test set. In order to analize the different performances of the methods, some evaluation metrics are used (such as confusion matrix, ROC curve). At the end of the project, the different accuracies and precisions are compared in a final plot, to identify which model can better classify the MNIST dataset.
"""

from sklearn.datasets import fetch_openml
mnist = fetch_openml(data_id=554) # https://www.openml.org/d/554

type(mnist.data), type(mnist.categories), type(mnist.feature_names), type(mnist.target)

mnist.data.shape, mnist.target.shape

mnist.data.shape, mnist.target.shape

"""The dataset contains 70.000 images 28x28(784)pixels

PREVIEW OF SOME IMAGES
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

"""We can work with a Numpay array, by converting the starting pandas dataframe"""

mnist_data_array = mnist.data.values

import matplotlib.pyplot as plt

plt.figure(figsize=(20, 4))
for index, (image, label) in enumerate(zip(mnist_data_array[0:4], mnist.target[0:4])):
    plt.subplot(1, 4, index + 1)
    plt.imshow(np.reshape(image, (28, 28)), cmap=plt.cm.gray)
    plt.title('Training: ' + label, fontsize=20)

plt.show()

"""Data preparation: the dataset is normalized by dividing each pixel by 255. This ensures that the pixel values are between 0 and 1 (the pixel values of grayscale images vary from 0 to 255)."""

mnist_data_array = mnist_data_array.astype('float32') / 255

mnist.target.astype('int')

"""```
# Questo è formattato come codice
```

TEST AND TRAINING SET SPLITTING
"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(mnist.data,
                                                    mnist.target.astype('int'), #targets str to int convert
                                                   test_size=1/10.0,
                                                   random_state=0)

x_train.shape, x_test.shape

"""If we want to be sure that the different classes are evenly distributed we can plot a histogram of the labels in both test and training set"""

plt.figure(figsize=(10,5))
plt.subplot(1,2,1)
plt.hist(y_train);
plt.title('Frequency of different classes - Training data');

plt.subplot(1,2,2)
plt.hist(y_test);
plt.title('Frequency of different classes - Test data');

"""# MNIST CLASSIFICATION WITH THE RIDGE CLASSIFIER METHOD

This classifier first converts the target values into {-1, 1} and then treats the problem as a regression task (multi-output regression in the multiclass case)

Model inizialization
"""

from sklearn.linear_model import RidgeClassifier

from sklearn.metrics import mean_squared_error

clf = RidgeClassifier()

"""Model training"""

clf.fit(x_train, y_train)

"""Predictions on the test set: the trained model can be used to predict test data using the .predict(x_test) method."""

predictions = clf.predict(x_test)

for i in range(50):
    print(f"Predicted: {predictions[i]}, Actual: {y_test.iloc[i]}")

from sklearn.metrics import accuracy_score, precision_score

# Make predictions on the training set
train_predictions = clf.predict(x_train)

# Accuracy calculation on the training set
train_accuracy = accuracy_score(y_train, train_predictions.round())
print(f"Training Accuracy: {train_accuracy}")

# Precision calculation on the training set
train_precision = precision_score(y_train, train_predictions.round(), average='weighted')
print(f"Training Precision: {train_precision}")

from sklearn.metrics import accuracy_score, precision_score

# Accuracy calculation on the test set
accuracy = accuracy_score(y_test, predictions.round())
print(f"Accuracy: {accuracy}")

# Precision calculation on the test set
precision = precision_score(y_test, predictions.round(), average='weighted')  #  'weighted' is specified for multiclasses classification problem
print(f"Precision: {precision}")

from sklearn.metrics import classification_report

# Classification report determination
class_report = classification_report(y_test, predictions.round(), target_names=[str(i) for i in range(10)])

# Print the classification report
print("Classification Report:\n", class_report)

"""The classification report gives information about:

Precision: it measures the fraction of true positives among instances that the model has classified as positive. In other words, it is the model's ability to not incorrectly label a negative instance as positive.
Precision = True Positives/(True Positives + False Positives)


Recall: it measures the fraction of positive instances that were correctly identified by the model. In other words, it is the model's ability to identify all positive instances.
Recall= True Positives/True Positives + False Negatives


F1-Score: it is the harmonic mean of precision and recall. It provides a balance between precision and recall. The F1-score is useful when you want a metric that takes into account both false positives and false negatives.
F1-Score=2x(Precision×Recall)/(Precision+Recall)

Support: it represents the number of samples for each class in the test set.

In this case the weighted average precision is 0.86,indicating a quite good precision of the model.
The accuracy is 0.86, which is the fraction of samples correctly classified.
The weighted average recall is 0.86, indicates a quite good ability of the model to correctly identify positive instances.
The weighted average F1-score is 0.85, which is the harmonic mean of precision and recall. From the classifier report it results that the worst predicted classes by the model are 4 and 1. The best one is 0
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import RidgeClassifier
from sklearn.metrics import accuracy_score, precision_score, classification_report

#Split the data
x_train, x_test, y_train, y_test = train_test_split(mnist.data,
                                                    mnist.target.astype('int'),
                                                    test_size=1/10.0,
                                                    random_state=0)

# Definition of the model
ridge_classifier = RidgeClassifier()

# Training
ridge_classifier.fit(x_train, y_train)

# Predictions on the test set
y_pred = ridge_classifier.predict(x_test)

# Accuracy calculation
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')

# Precision for each class
precision_per_class = precision_score(y_test, y_pred, average=None)
print('Precision per class:')
for i, precision in enumerate(precision_per_class):
    print(f'Class {i}: {precision}')

# Print the classification report
print('\nClassification Report:')
print(classification_report(y_test, y_pred))

"""# MNIST CLASSIFICATION WITH THE LOGISTIC REGRESSION MODEL

"""

from sklearn.linear_model import LogisticRegression

clf2 = LogisticRegression(
    fit_intercept=True,
    multi_class='auto',
    penalty='l1',  # Use of regularization L1 (Lasso)
    solver='saga',
    max_iter=1000,
    C=1,
    verbose=2,  # output progress
    n_jobs=5,  # parallelize over 5 processes
    tol=0.01
)
clf2

# Commented out IPython magic to ensure Python compatibility.
# %%time
# clf2.fit(x_train, y_train)

clf2.classes_

clf2.coef_.shape

clf2.coef_[1].round(3) # prints weights for 8x8 image for class 0

clf2.intercept_ # for 10 classes - this is a One-vs-All classification

clf2.n_iter_[0] # num of iterations before tolerance was reached

coef = clf2.coef_.copy()
scale = np.abs(coef).max()
plt.figure(figsize=(13,7))

for i in range(10): # 0-9
    coef_plot = plt.subplot(2, 5, i + 1) # 2x5 plot

    coef_plot.imshow(coef[i].reshape(28,28),
                     cmap=plt.cm.RdBu,
                     vmin=-scale, vmax=scale,
                    interpolation='bilinear')

    coef_plot.set_xticks(()); coef_plot.set_yticks(())
    coef_plot.set_xlabel(f'Class {i}')

plt.suptitle('Coefficients for various classes');

print(clf2.predict(x_test[0:9]))
print(y_test[0:9])

# Make predictions on the test set
predictions = clf2.predict(x_test)

# Visualize the first 10 predictions with rispect to the real values
for i in range(50):
    print(f"Predicted: {predictions[i]}, Actual: {y_test.iloc[i]}")

from sklearn.metrics import accuracy_score, precision_score

# Make predictions on training set
predictions = clf2.predict(x_train)

# Accuracy calculation
accuracy = accuracy_score(y_train, predictions)
print(f"Accuracy: {accuracy}")

# Precision calculation
precision = precision_score(y_train, predictions, average='weighted')
print(f"Precision: {precision}")

from sklearn.metrics import accuracy_score, precision_score

# Make predictions on the test set
predictions = clf2.predict(x_test)

# Accuracy calculation
accuracy = accuracy_score(y_test, predictions)
print(f"Accuracy: {accuracy}")

# Precision calculation
precision = precision_score(y_test, predictions, average='weighted')
print(f"Precision: {precision}")

from sklearn.metrics import classification_report

# Compute the classification report
class_report = classification_report(y_test, predictions.round(), target_names=[str(i) for i in range(10)])

#Print the classification report
print("Classification Report:\n", class_report)

"""The logistic regression model results better than the RidgeClassifier. Actually, both the total precision and the accuracy increase. In particular, the accuracy per class is higher than the RidgeClassifier one. Moreover, in this case, the classes that have the lowest precision are the 8 and 9

Evaluation metrics: confusion matrix
"""

from sklearn import metrics

predictions2 = clf2.predict(x_test)

cm = metrics.confusion_matrix(y_true=y_test,
                         y_pred = predictions2,
                        labels = clf2.classes_)
cm

from sklearn.metrics import accuracy_score
# Assume that 'y_true' is the real label and 'y_pred' is the label predicted by your model
y_true = y_test
y_pred = predictions2

# Calculate accuracy and assign value to 'score2'
score2 = accuracy_score(y_true, y_pred)


plt.figure(figsize=(12, 12))
sns.heatmap(cm, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='0.4g')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(score2)
plt.title(all_sample_title)
plt.show()

# Identification of the wrong predictions indexes
misclassified_idx = np.where(y_true != y_pred)[0]

# Visualization of  the first 15 misclassified images
plt.figure(figsize=(15, 6))
for i, idx in enumerate(misclassified_idx[:15]):
    plt.subplot(3, 5, i + 1)
    plt.imshow(x_test.iloc[idx].values.reshape((28, 28)), cmap='gray')
    plt.title(f'True: {y_true.iloc[idx]}, Predicted: {y_pred[idx]}')
    plt.axis('off')

plt.show()

from sklearn.metrics import classification_report

# Make predictions on the test set
predictions = clf2.predict(x_test)

# Generate the classification report
report = classification_report(y_test, predictions, output_dict=True)

# Extract precision for each class from the classification report
precisions_per_class = {str(int(cls)): report[str(int(cls))]['precision'] for cls in clf2.classes_}

# Print the precision for each class
print('Precision per class:')
for cls, precision in precisions_per_class.items():
    print(f'Class {cls}: {precision}')

"""EVALUATION METRICS: ROC curve"""

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import matplotlib.pyplot as plt

# Turn labels into binary shapes
y_test_bin = label_binarize(y_test, classes=clf2.classes_)

# Class probability predictions on the test set
y_probs = clf2.predict_proba(x_test)

# ROC curve for each class
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(len(clf2.classes_)):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Visualization of the ROC curve for each class
plt.figure(figsize=(8, 6))
for i in range(len(clf2.classes_)):
    plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')

# Legend
plt.legend(loc='lower right')

# Axes labels
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Multi-Class')

y_test_array = y_test.to_numpy()

print(y_test_array.shape)

y_test_array = y_test_array.squeeze()

from sklearn.metrics import roc_auc_score

# Assuming y_probs contains predicted probabilities for the specific class
# y_test_array should contain the actual class labels (0, 1, 2, ..., 9 for each class
auc_scores = []

n_classi = 10  # Number of classes

for i in range(n_classi):
    auc_i = roc_auc_score((y_test_array == i).astype(int), y_probs[:, i])
    auc_scores.append(auc_i)

print(f'AUC per classe: {auc_scores}')

"""The AUC (Area Under the Curve) is a measure of a model's discriminatory ability. A value of AUC close to 1 indicates a model with excellent discriminatory ability, while a value close to 0.5 suggests that the model struggles to discriminate between classes. Values above 0.5 indicate good discrimination, while values below 0.5 suggest that the model is performing worse than random chance.

In general:

Values close to 1: Good discrimination between the positive and negative class. The model effectively separates the classes.
Values close to 0.5: The model struggles to effectively discriminate between the positive and negative class. It might be equivalent to a random classifier.
Values below 0.5: The model is performing worse than random chance. There may be an issue with how the model is trained or with the dataset.
Furthermore, comparing the AUC values across different classes can provide insights into which classes the model handles better or worse in terms of discrimination.

In this case, the AUC values seem to be very close to 1 for all classes, indicating excellent discriminatory ability for your model across all classes. This is a positive sign, suggesting that the logistic regression model is doing well in classifying the different classes in your problem.

TRAINING AND TEST SET SIZE CHANGE

We can try to increase the dimension of the test test
"""

from sklearn.model_selection import train_test_split
x1_train, x1_test, y1_train, y1_test = train_test_split(mnist.data,
                                                    mnist.target.astype('int'), #targets str to int convert
                                                   test_size=1/7.0,
                                                   random_state=0)

x1_train.shape, x1_test.shape

from sklearn.linear_model import LogisticRegression

clf2 = LogisticRegression(
    fit_intercept=True,
    multi_class='auto',
    penalty='l1',  # Use of regularization L1 (Lasso)
    solver='saga',
    max_iter=1000,
    C=1,
    verbose=2,  # output progress
    n_jobs=5,  # parallelize over 5 processes
    tol=0.01
)
clf2

clf2.fit(x1_train, y1_train)

predictions = clf2.predict(x1_test)

clf2.classes_

clf2.coef_[1].round(3) # prints weights for 8x8 image for class 0

print(clf2.predict(x1_test[0:9]))
print(y1_test[0:9])

from sklearn.metrics import accuracy_score, precision_score

# Make predictions on the train set
predictions = clf2.predict(x1_train)

# Accuracy calculation
accuracy = accuracy_score(y1_train, predictions)
print(f"Accuracy: {accuracy}")

# Precision calculation
precision = precision_score(y1_train, predictions, average='weighted')
print(f"Precision: {precision}")

from sklearn.metrics import accuracy_score, precision_score

#Make predictions on the test set
predictions = clf2.predict(x1_test)

# Accuracy calculation
accuracy = accuracy_score(y1_test, predictions)
print(f"Accuracy: {accuracy}")

# Precision calculation
precision = precision_score(y1_test, predictions, average='weighted')
print(f"Precision: {precision}")

"""If we increase the size of the test set we can notice a decrease of the accuracy and the precision on the test set. There are several considerations that might explain this behavior:

*   representativeness of the Test Set: with a larger test set, it's important to ensure that it is representative of the distribution of input data. If the larger test set contains patterns or variations not present in the training set, the model may not generalize well, leading to a decrease in performance.
Variation in test Set characteristics: if there are significant differences in the characteristics of the larger test set compared to the smaller one, the model may struggle to generalize effectively to new data, resulting in decreased performance.

* Initial Overfitting: the model may have experienced overfitting during training on the smaller training set. When exposed to a larger test set, it might become evident that the model had memorized specific details of the training set rather than learning general patterns.

* Model Complexity: a model that is too complex may overfit to the training data, reducing its ability to generalize to new data. Having a larger test set could expose this issue.

We can try to understand the reason why the accuracy and the precion decrease with some tests, like visulize the missclassified examples with a confusion matrix or we can display the missclassified images

"""

from sklearn.metrics import accuracy_score, precision_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Make predictions on the test set
predictions = clf2.predict(x1_test)

# Accuracy calculation
accuracy = accuracy_score(y1_test, predictions)
print(f"Accuracy: {accuracy}")

# Precision calculation
precision = precision_score(y1_test, predictions, average='weighted')
print(f"Precision: {precision}")

# Assuming 'y1_test' is the true labels for the test set
y1_true = y1_test[:len(predictions)]

# Calculate accuracy using the same predictions for consistency
score2 = accuracy_score(y1_true, predictions)
print(f"Consistent Accuracy: {score2}")

# Plot confusion matrix
cm = confusion_matrix(y1_true, predictions)
plt.figure(figsize=(12, 12))
sns.heatmap(cm, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='0.4g')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(score2)
plt.title(all_sample_title)
plt.show()

misclassified_idx = np.where(y1_true != predictions)[0]

plt.figure(figsize=(12, 6))
for i, idx in enumerate(misclassified_idx[:10]):
    plt.subplot(2, 5, i + 1)
    # Use iloc to access the DataFrame by numerical index
    plt.imshow(x1_test.iloc[idx].values.reshape((28, 28)), cmap='gray')
    plt.title(f'True: {y1_true.iloc[idx]}, Predicted: {predictions[idx]}')
    plt.axis('off')

plt.show()

"""# LOGISTIC REGRESSION MODEL IMPLEMENTATION: K-folds procedure

To reduce the probable overfitting a procedure called cross-validation is tested. In the basic approach, called k-fold CV, the training set is split into k smaller sets known as k-folds; the model is trained using k - 1 folds as training data;
the resulting model is validated on the remaining part of the data.

"""

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_predict
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# Create a pipeline with data scaling and logistic regression
model = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs', max_iter=5000))

# Set up k-fold cross-validation (5 folds)
num_folds = 5
seed = 7
kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)

# Perform cross-validation and get predictions
y_pred_cv = cross_val_predict(model, x_train, y_train, cv=kfold)

# Calculate accuracy and precision for each fold
accuracy_per_fold = accuracy_score(y_train, y_pred_cv)
precision_per_fold = precision_score(y_train, y_pred_cv, average='weighted')

# Print average accuracy and precision
print(f"Average Accuracy: {accuracy_per_fold.mean()}")
print(f"Average Precision: {precision_per_fold.mean()}")

# Assuming 'y_train' is the true labels for the training set
# Calculate accuracy using the same predictions for consistency
consistent_accuracy = accuracy_score(y_train, y_pred_cv)
print(f"Consistent Accuracy: {consistent_accuracy}")

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_train, y_pred_cv)

# Plot confusion matrix
plt.figure(figsize=(12, 12))
sns.heatmap(conf_matrix, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='0.4g')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(consistent_accuracy)
plt.title(all_sample_title)
plt.show()

"""EVALUATION METRICS: ROC curve"""

from sklearn.model_selection import KFold, cross_val_predict
from sklearn.metrics import roc_curve, auc
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
import matplotlib.pyplot as plt

# Create a pipeline with data scaling and logistic regression
model = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs', max_iter=5000))

# Set up k-fold cross-validation (5 folds)
num_folds = 5
seed = 7
kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)

# Get cross-validated predicted probabilities
y_probs_cv = cross_val_predict(model, x_train, y_train, cv=kfold, method='predict_proba')

# Initialize plot
plt.figure(figsize=(8, 6))

# List to store AUC scores for each class
auc_scores = []

# For each class
for i in range(10):
    # Compute ROC curve and AUC for each fold
    fpr, tpr, _ = roc_curve((y_train == i), y_probs_cv[:, i])
    roc_auc = auc(fpr, tpr)

    # Append AUC score to the list
    auc_scores.append(roc_auc)

    # Plot ROC curve for each fold
    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')

# Plot random guessing (no skill)
plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random Guessing')

# Set plot labels
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Cross-Validated')
plt.legend(loc='lower right')
plt.show()

# Print AUC scores for each class
print("AUC per classe:", auc_scores)

"""We can try to improve the model by increasing the number of folds"""

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_predict
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# Create a pipeline with data scaling and logistic regression
model = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs', max_iter=5000))

# Set up k-fold cross-validation (10 folds)
num_folds = 10
seed = 7
kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)

# Perform cross-validation and get predictions
y_pred_cv = cross_val_predict(model, x_train, y_train, cv=kfold)

# Calculate accuracy and precision for each fold
accuracy_per_fold = accuracy_score(y_train, y_pred_cv)
precision_per_fold = precision_score(y_train, y_pred_cv, average='weighted')

# Print average accuracy and precision
print(f"Average Accuracy: {accuracy_per_fold.mean()}")
print(f"Average Precision: {precision_per_fold.mean()}")

# Assuming 'y_train' is the true labels for the training set
# Calculate accuracy using the same predictions for consistency
consistent_accuracy = accuracy_score(y_train, y_pred_cv)
print(f"Consistent Accuracy: {consistent_accuracy}")

# Calculate confusion matrix
conf_matrix = confusion_matrix(y_train, y_pred_cv)

# Plot confusion matrix
plt.figure(figsize=(12, 12))
sns.heatmap(conf_matrix, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='0.4g')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(consistent_accuracy)
plt.title(all_sample_title)
plt.show()

"""In this way we demostrated that if we increase the number of folds, the accuracy increase

# MNIST CLASSIFICATION WITH DECISION TREE MODEL
Decision Trees (DTs) are a non-parametric supervised learning method whose goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. A tree can be seen as a piecewise constant approximation.
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Create a Decision Tree model
dtree = DecisionTreeClassifier()
dtree.fit(x_train, y_train)

# Make predictions on the test set
y_pred_test = dtree.predict(x_test)

# Make predictions on the train set (optional)
y_pred_train = dtree.predict(x_train)

# Calculate accuracy on test set
accuracy_test = accuracy_score(y_test, y_pred_test)
print(f"Accuracy on test set: {accuracy_test}")

# Calculate accuracy on train set (optional)
accuracy_train = accuracy_score(y_train, y_pred_train)
print(f"Accuracy on train set: {accuracy_train}")

from sklearn.metrics import classification_report, confusion_matrix

# Make predictions on the test set
y_pred_test = dtree.predict(x_test)

# Confusion matrix and classification report for Decision Tree model
cm_dtree = confusion_matrix(y_test, y_pred_test)
classification_report_dtree = classification_report(y_test, y_pred_test)

print("Confusion Matrix:")
print(cm_dtree)

print("\nClassification Report:")
print(classification_report_dtree)

# Accuracy calculation for Decision Tree
accuracy_dtree = accuracy_score(y_test, y_pred_test)
print(f"\nDecision Tree Accuracy: {accuracy_dtree}")

from sklearn.metrics import accuracy_score, precision_score
import seaborn as sns
import matplotlib.pyplot as plt

# Accuracy calculation for Decision Tree
accuracy_dtree = accuracy_score(y_test, y_pred_test)
print(f"Decision Tree Accuracy: {accuracy_dtree}")

# Precision calculation for Decision Tree
precision_dtree = precision_score(y_test, y_pred_test, average='weighted')
print(f"Decision Tree Precision: {precision_dtree}")

# Plot confusion matrix for Decision Tree
plt.figure(figsize=(12, 12))
sns.heatmap(cm_dtree, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='d')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title_dtree = 'Decision Tree Accuracy Score: {0}'.format(accuracy_dtree)
plt.title(all_sample_title_dtree)
plt.show()

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

mnist_data_array = mnist.data.values
mnist_data_array = mnist_data_array.astype('float32') / 255

x_train, x_test, y_train, y_test = train_test_split(mnist_data_array,
                                                    mnist.target.astype('int'),
                                                    test_size=1/10.0,
                                                    random_state=0)

# Convertion of x_test in a NumPy array
x_test = np.array(x_test)

# Dimension analysis
print(x_train.shape, x_test.shape)

# Create a Decision Tree model
dtree = DecisionTreeClassifier()
dtree.fit(x_train, y_train)

# Make predictions on the test set
y_pred_test = dtree.predict(x_test)

# Convertion of the y_test in a  NumPy array
y_test = np.array(y_test)

# Identify missclassified classes indexes
misclassified_idx = np.where(y_test != y_pred_test)[0]

# Visualization of the first 15 misclassified images
plt.figure(figsize=(15, 6))
for i, idx in enumerate(misclassified_idx[:15]):
    plt.subplot(3, 5, i + 1)
    plt.imshow(x_test[idx].reshape((28, 28)), cmap='gray')
    plt.title(f'True: {y_test[idx]}, Predicted: {y_pred_test[idx]}')
    plt.axis('off')

plt.show()

from sklearn.metrics import classification_report

# Make predictions on the test set
predictions_dtree = dtree.predict(x_test)

# Generate the classification report
report_dtree = classification_report(y_test, predictions_dtree, output_dict=True)

# Extract precision for each class from the classification report
precisions_per_class_dtree = {str(int(cls)): report_dtree[str(int(cls))]['precision'] for cls in dtree.classes_}

# Print the precision for each class
print('Precision per class for Decision Tree:')
for cls, precision in precisions_per_class_dtree.items():
    print(f'Class {cls}: {precision}')

"""# MNIST CLASSIFICATION WITH RANDOM FOREST MODEL

Random forest model combines the output of multiple decision trees to reach a single result.
"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(mnist.data,
                                                    mnist.target.astype('int'), #targets str to int convert
                                                   test_size=1/10.0,
                                                   random_state=0)

from sklearn.ensemble import RandomForestClassifier  #Random Forest algorithm

#training random Forest
rf=RandomForestClassifier(n_estimators=100)
rf.fit(x_train,y_train)

pred=rf.predict(x_test)
print ("Classification Report")
print(classification_report(y_test, pred))
print ("Confusion Report")
print(confusion_matrix(y_test, pred))

# Make predictions on the test set
predictions = rf.predict(x_test)

# Accuracy calculation
accuracy = accuracy_score(y_test, predictions)
print(f"Accuracy: {accuracy}")

# Precision calculation
precision = precision_score(y_test, predictions, average='weighted')
print(f"Precision: {precision}")

# Assuming 'y_test' is the true labels for the test set
y_true = y_test[:len(predictions)]

# Calculate accuracy using the same predictions for consistency
consistent_accuracy = accuracy_score(y_true, predictions)
print(f"Consistent Accuracy: {consistent_accuracy}")

# Plot confusion matrix
cm = confusion_matrix(y_true, predictions)
plt.figure(figsize=(12, 12))
sns.heatmap(cm, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='0.4g')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(consistent_accuracy)
plt.title(all_sample_title)
plt.show()

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
import matplotlib.pyplot as plt

mnist_data_array = mnist.data.values
mnist_data_array = mnist_data_array.astype('float32') / 255

x_train, x_test, y_train, y_test = train_test_split(mnist_data_array,
                                                    mnist.target.astype('int'),
                                                    test_size=1/10.0,
                                                    random_state=0)

# Create a Random Forest model
rf = RandomForestClassifier(n_estimators=100)
rf.fit(x_train, y_train)

# Make predictions on the test set
y_pred_test = rf.predict(x_test)

# Convert y_test to a NumPy array
y_test = np.array(y_test)

# Find misclassified indexes
misclassified_idx = np.where(y_test != y_pred_test)[0]

# Visualization of the first 15 misclassified images
plt.figure(figsize=(15, 6))
for i, idx in enumerate(misclassified_idx[:15]):
    plt.subplot(3, 5, i + 1)
    plt.imshow(x_test[idx].reshape((28, 28)), cmap='gray')
    plt.title(f'True: {y_test[idx]}, Predicted: {y_pred_test[idx]}')
    plt.axis('off')

plt.show()

from sklearn.metrics import classification_report

# Make predictions on the test set
predictions_rf = rf.predict(x_test)

# Generate the classification report
report_rf = classification_report(y_test, predictions_rf, output_dict=True)

# Extract precision for each class from the classification report
precisions_per_class_rf = {str(int(cls)): report_rf[str(int(cls))]['precision'] for cls in rf.classes_}

# Print the precision for each class
print('Precision per class for Random Forest:')
for cls, precision in precisions_per_class_rf.items():
    print(f'Class {cls}: {precision}')

"""# MNIST CLASSIFICATION WITH SVM MODEL

Support Vector Machine (SVM) is a supervised machine learning algorithm used for both classification and regression. In this case it is used for a classification problem. The main objective of the SVM algorithm is to find the optimal hyperplane in an N-dimensional space that can separate the data points in different classes in the feature space. The hyperplane tries that the margin between the closest points of different classes should be as maximum as possible. The dimension of the hyperplane depends upon the number of features.
"""

from sklearn.svm import SVC, LinearSVC

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(mnist.data,
                                                    mnist.target.astype('int'), #targets str to int convert
                                                   test_size=1/10.0,
                                                   random_state=0)

from sklearn.svm import SVC
from sklearn.metrics import accuracy_score


# Create an SVM model
svm_model = SVC()

# Train the model on the training set
svm_model.fit(x_train, y_train)

# Make predictions on the test set
predictions = svm_model.predict(x_test)

# Compute the accuracy
accuracy = accuracy_score(y_test, predictions)
print(f"Accuracy: {accuracy}")

from sklearn.metrics import confusion_matrix
from sklearn.metrics import confusion_matrix, classification_report
# Make predictions on the test set
predictions_svm = svm_model.predict(x_test)

# Confusion matrix and classification report for SVM model
cm_svm = confusion_matrix(y_test, predictions_svm)
classification_report_svm = classification_report(y_test, predictions_svm)

print("Confusion Matrix:")
print(cm_svm)

print("\nClassification Report:")
print(classification_report_svm)

# Accuracy calculation for SVM
accuracy_svm = accuracy_score(y_test, predictions_svm)
print(f"\nSVM Accuracy: {accuracy_svm}")

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
import matplotlib.pyplot as plt

mnist_data_array = mnist.data.values
mnist_data_array = mnist_data_array.astype('float32') / 255

x_train, x_test, y_train, y_test = train_test_split(mnist_data_array,
                                                    mnist.target.astype('int'),
                                                    test_size=1/10.0,
                                                    random_state=0)

# Create an SVM model
svm_model = SVC()

# Train the model on the training set
svm_model.fit(x_train, y_train)

# Make predictions on the test set
predictions = svm_model.predict(x_test)

# Convert y_test to a NumPy array
y_test = np.array(y_test)

# Find misclassified indexes
misclassified_idx = np.where(y_test != predictions)[0]

# Visualization of the first 15 misclassified images
plt.figure(figsize=(15, 6))
for i, idx in enumerate(misclassified_idx[:15]):
    plt.subplot(3, 5, i + 1)
    plt.imshow(x_test[idx].reshape((28, 28)), cmap='gray')
    plt.title(f'True: {y_test[idx]}, Predicted: {predictions[idx]}')
    plt.axis('off')

plt.show()

from sklearn.metrics import classification_report

# Make predictions on the test set using the SVM model
predictions_svm = svm_model.predict(x_test)

# Generate the classification report
report_svm = classification_report(y_test, predictions_svm, output_dict=True)

# Extract precision for each class from the classification report
precisions_per_class_svm = {str(int(cls)): report_svm[str(int(cls))]['precision'] for cls in svm_model.classes_}

# Print the precision for each class
print('Precision per class for SVM:')
for cls, precision in precisions_per_class_svm.items():
    print(f'Class {cls}: {precision}')

"""EVALUATION METRICS: confusion matrix"""

# Accuracy calculation for SVM
accuracy_svm = accuracy_score(y_test, predictions_svm)
print(f"SVM Accuracy: {accuracy_svm}")

# Precision calculation for SVM
precision_svm = precision_score(y_test, predictions_svm, average='weighted')
print(f"SVM Precision: {precision_svm}")

# Assuming 'y_test' is the true labels for the test set for SVM
y_true_svm = y_test[:len(predictions_svm)]

# Calculate accuracy using the same predictions for consistency for SVM
consistent_accuracy_svm = accuracy_score(y_true_svm, predictions_svm)
print(f"SVM Consistent Accuracy: {consistent_accuracy_svm}")

# Plot confusion matrix for SVM
cm_svm = confusion_matrix(y_true_svm, predictions_svm)
plt.figure(figsize=(12, 12))
sns.heatmap(cm_svm, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='0.4g')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title_svm = 'SVM Accuracy Score: {0}'.format(consistent_accuracy_svm)
plt.title(all_sample_title_svm)
plt.show()

"""# MNIST CLASSIFICATION WITH A CNN


A convolutional neural network is  used to analyze visual images by processing data with grid-like topology.  A convolutional neural network is used to detect and classify objects in an image.
A convolution neural network has multiple hidden layers that help in extracting information from an image. The four important layers in CNN are:

*   Convolution layer

*   ReLU layer

*   Pooling layer

*   Fully connected layer
"""

import numpy as np
import keras
from keras.datasets import mnist
from keras.models import Model
from keras.layers import Dense, Input
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten
from keras import backend as k

from keras.datasets import mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()

#reshape data to fit model
X_train = X_train.reshape(60000,28,28,1)
X_test = X_test.reshape(10000,28,28,1)

#OLD from keras.utils import to_categorical
from tensorflow.keras.utils import to_categorical
#one-hot encode target column
y_train_OHE = to_categorical(y_train)
y_test_OHE = to_categorical(y_test)

from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten

#create model
model = Sequential()
#add model layers
model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))
model.add(Conv2D(32, kernel_size=3, activation='relu'))
model.add(Flatten())
model.add(Dense(10, activation='softmax'))

#compile model using accuracy to measure model performance
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# #train the model
# model.fit(X_train, y_train_OHE, validation_data=(X_test, y_test_OHE), epochs=3)

model.predict(X_test[:10])

y_test_OHE[:10]

y_test[0]

y_test[1]

y_test[10]

import numpy as np
import keras
from keras.datasets import mnist
from keras.models import Model
from keras.layers import Dense, Input
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten
from keras import backend as k
from keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten
from sklearn.metrics import classification_report, confusion_matrix

# predict on the test set
y_pred = model.predict(X_test)

# convert predictions to labels
y_pred_labels = np.argmax(y_pred, axis=1)

# convert one-hot encoded labels back to categorical labels
y_test_labels = np.argmax(y_test_OHE, axis=1)

# print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test_labels, y_pred_labels))

# print classification report
print("Classification Report:")
print(classification_report(y_test_labels, y_pred_labels))

"""EVALUATION METRICS: confusion matrix"""

from sklearn.metrics import accuracy_score, precision_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Make predictions on the test set using the CNN model
predictions_cnn_prob = model.predict(X_test)
predictions_cnn = np.argmax(predictions_cnn_prob, axis=1)

# Convert one-hot encoded labels back to categorical labels
y_test_labels = np.argmax(y_test_OHE, axis=1)

# Calculate accuracy
accuracy_cnn = accuracy_score(y_test_labels, predictions_cnn)
print(f"CNN Accuracy: {accuracy_cnn}")

# Calculate precision
precision_cnn = precision_score(y_test_labels, predictions_cnn, average='weighted')
print(f"CNN Precision: {precision_cnn}")

# Plot confusion matrix
cm_cnn = confusion_matrix(y_test_labels, predictions_cnn)
plt.figure(figsize=(12, 12))
sns.heatmap(cm_cnn, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='0.4g')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title_cnn = 'CNN Accuracy Score: {0}'.format(accuracy_cnn)
plt.title(all_sample_title_cnn)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Make predictions on the test set
predictions_cnn_prob = model.predict(X_test)
predictions_cnn = np.argmax(predictions_cnn_prob, axis=1)  # Ottieni le etichette di classe predette

# Find misclassified indexes
misclassified_idx = np.where(y_test != predictions_cnn)[0]

# Visualization of the first 15 misclassified images
plt.figure(figsize=(15, 6))
for i, idx in enumerate(misclassified_idx[:15]):
    plt.subplot(3, 5, i + 1)
    plt.imshow(X_test[idx].reshape((28, 28)), cmap='gray')
    plt.title(f'True: {y_test[idx]}, Predicted: {predictions_cnn[idx]}')
    plt.axis('off')

plt.show()

from sklearn.metrics import classification_report

# Make predictions on the test set using the CNN model
predictions_cnn_prob = model.predict(X_test)
predictions_cnn = np.argmax(predictions_cnn_prob, axis=1)

# Convert one-hot encoded labels back to categorical labels
y_test_labels = np.argmax(y_test_OHE, axis=1)

# Generate the classification report
report_cnn = classification_report(y_test_labels, predictions_cnn, output_dict=True)

# Extract precision for each class from the classification report
precisions_per_class_cnn = {str(int(cls)): report_cnn[str(int(cls))]['precision'] for cls in range(10)}

# Print the precision for each class
print('Precision per class for CNN:')
for cls, precision in precisions_per_class_cnn.items():
    print(f'Class {cls}: {precision}')

"""The same model can be tested increasing the number of epochs"""

import numpy as np
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten
from keras.utils import to_categorical

# Load the MNIST dataset
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Reshape data to fit the model
X_train = X_train.reshape(60000, 28, 28, 1)
X_test = X_test.reshape(10000, 28, 28, 1)

# One-hot encode target column
y_train_OHE = to_categorical(y_train)
y_test_OHE = to_categorical(y_test)

# Create the CNN model
model = Sequential()
model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))
model.add(Conv2D(32, kernel_size=3, activation='relu'))
model.add(Flatten())
model.add(Dense(10, activation='softmax'))

# Compile the model using accuracy to measure model performance
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model with 10 epochs
history = model.fit(X_train, y_train_OHE, validation_data=(X_test, y_test_OHE), epochs=10)

model.predict(X_test[:10])

y_test_OHE[:10]

import numpy as np
import keras
from keras.datasets import mnist
from keras.models import Model
from keras.layers import Dense, Input
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten
from keras import backend as k
from keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten
from sklearn.metrics import classification_report, confusion_matrix

# predict on the test set
y_pred = model.predict(X_test)

# convert predictions to labels
y_pred_labels = np.argmax(y_pred, axis=1)

# convert one-hot encoded labels back to categorical labels
y_test_labels = np.argmax(y_test_OHE, axis=1)

# print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test_labels, y_pred_labels))

# print classification report
print("Classification Report:")
print(classification_report(y_test_labels, y_pred_labels))

from sklearn.metrics import accuracy_score, precision_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns



# predict on the test set
y_pred = model.predict(X_test)

# convert predictions to labels
y_pred_labels = np.argmax(y_pred, axis=1)

# convert one-hot encoded labels back to categorical labels
y_test_labels = np.argmax(y_test_OHE, axis=1)

# Accuracy calculation
accuracy_cnn = accuracy_score(y_test_labels, y_pred_labels)
print(f"CNN Accuracy: {accuracy_cnn}")

# Precision calculation
precision_cnn = precision_score(y_test_labels, y_pred_labels, average='weighted')
print(f"CNN Precision: {precision_cnn}")

# Assuming 'y_test_labels' is the true labels for the test set for CNN
y_true_cnn = y_test_labels[:len(y_pred_labels)]

# Calculate accuracy using the same predictions for consistency
consistent_accuracy_cnn = accuracy_score(y_true_cnn, y_pred_labels)
print(f"CNN Consistent Accuracy: {consistent_accuracy_cnn}")

# Plot confusion matrix
cm_cnn = confusion_matrix(y_true_cnn, y_pred_labels)
plt.figure(figsize=(12, 12))
sns.heatmap(cm_cnn, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='0.4g')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title_cnn = 'CNN Accuracy Score: {0}'.format(consistent_accuracy_cnn)
plt.title(all_sample_title_cnn)
plt.show()

# Make predictions on the test set
predictions_nn_prob = model.predict(X_test)
predictions_nn = np.argmax(predictions_nn_prob, axis=1)

# Find misclassified classes
misclassified_idx = np.where(y_test != predictions_nn)[0]

# Display the first 15 misclassified images
plt.figure(figsize=(15, 6))
for i, idx in enumerate(misclassified_idx[:15]):
    plt.subplot(3, 5, i + 1)
    plt.imshow(X_test[idx].reshape((28, 28)), cmap='gray')
    plt.title(f'True: {y_test[idx]}, Predicted: {predictions_nn[idx]}')
    plt.axis('off')

plt.show()

from sklearn.metrics import classification_report

# Make predictions on the test set using the trained model
predictions_prob = model.predict(X_test)
predictions = np.argmax(predictions_prob, axis=1)

# Convert one-hot encoded labels back to categorical labels
y_test_labels = np.argmax(y_test_OHE, axis=1)

# Generate the classification report
report = classification_report(y_test_labels, predictions, output_dict=True)

# Extract precision for each class from the classification report
precisions_per_class = {str(int(cls)): report[str(int(cls))]['precision'] for cls in range(10)}

# Print the precision for each class
print('Precision per class:')
for cls, precision in precisions_per_class.items():
    print(f'Class {cls}: {precision}')

"""As noted by the classification report increasing the number of epochs from 3 to 10 does not lead to a clear improvement in accuracy. When accuracy reaches a plateau, increasing the number of epochs may not lead to significant improvements, as the model has already learned most of the relevant information in the training data. the model has already gone to convergence

Increasing the number of epochs can lead to a longer training and therefore an increase in the production time of the results without necessarily improving the performance of the model. It is important to balance the trade-off between the desired accuracy and the available training time. If we want to improve the accuracy we can try the hyperparameter tuning experiments with different hyperparameters such as learning rate, convolutional filter size, number of units in dense layers, etc and uses techniques such as grid search or random search to find the optimal combination of hyperparameters.
"""

import numpy as np
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from keras.optimizers import Adam, SGD
from keras.datasets import mnist
from keras.utils import to_categorical
from sklearn.metrics import accuracy_score

# Load and preprocess data
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train = X_train.reshape(-1, 28, 28, 1) / 255.0
X_test = X_test.reshape(-1, 28, 28, 1) / 255.0
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Define the CNN model function
def create_model(fc_layer_size=128, dropout=0.3, optimizer='adam', learning_rate=0.001):
    model = Sequential()
    model.add(Conv2D(32, (3, 3), input_shape=(28, 28, 1), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(fc_layer_size, activation='relu'))
    model.add(Dropout(dropout))
    model.add(Dense(10, activation='softmax'))

    if optimizer == 'adam':
        optimizer = Adam(learning_rate=learning_rate)
    else:
        optimizer = SGD(learning_rate=learning_rate)

    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Define a function to calculate accuracy
def calculate_accuracy(model, X, y):
    y_pred_prob = model.predict(X)
    y_pred = np.argmax(y_pred_prob, axis=1)
    return accuracy_score(np.argmax(y, axis=1), y_pred)
# Define the parameter distributions for randomized search
param_distributions = {
    'learning_rate': [0.001, 0.01, 0.1],
    'fc_layer_size': [128, 256, 512],
    'dropout': [0.3, 0.4, 0.5]
}

# Perform random search manually
best_accuracy = 0
best_params = None
for _ in range(10):  # Number of iterations for random search
    params = {param: np.random.choice(values) for param, values in param_distributions.items()}
    model = create_model(**params)
    model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=0)  # Adjust batch size here
    accuracy = calculate_accuracy(model, X_test, y_test)
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        best_params = params

# Print the best parameters
print("Best parameters:", best_params)

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from keras.optimizers import Adam
from keras.datasets import mnist
from keras.utils import to_categorical

# Load and preprocess data
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train = X_train.reshape(-1, 28, 28, 1) / 255.0
X_test = X_test.reshape(-1, 28, 28, 1) / 255.0
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# Define the best parameters obtained from hyperparameter tuning
best_params = {'learning_rate': 0.001, 'fc_layer_size': 512, 'dropout': 0.4}

# Define and compile the model with the best parameters
model = create_model(**best_params)
optimizer = Adam(learning_rate=best_params['learning_rate'])
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model with the best parameters
model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))

# Evaluate the model on test data
test_loss, test_accuracy = model.evaluate(X_test, y_test)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# Get model predictions on test data
y_pred_probabilities = model.predict(X_test)
y_pred = np.argmax(y_pred_probabilities, axis=1)

# Print the classification report
print("Classification Report:")
print(classification_report(y_test_labels, y_pred))

# Calculate and print the confusion matrix
conf_matrix = confusion_matrix(y_test_labels, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

from sklearn.metrics import accuracy_score, precision_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# predict on the test set
y_pred = model.predict(X_test)

# convert predictions to labels
y_pred_labels = np.argmax(y_pred, axis=1)

# convert one-hot encoded labels back to categorical labels
y_test_labels = np.argmax(y_test_OHE, axis=1)

# Accuracy calculation
accuracy_cnn = accuracy_score(y_test_labels, y_pred_labels)
print(f"CNN Accuracy: {accuracy_cnn}")

# Precision calculation
precision_cnn = precision_score(y_test_labels, y_pred_labels, average='weighted')
print(f"CNN Precision: {precision_cnn}")

# Assuming 'y_test_labels' is the true labels for the test set for CNN
y_true_cnn = y_test_labels[:len(y_pred_labels)]

# Calculate accuracy using the same predictions for consistency
consistent_accuracy_cnn = accuracy_score(y_true_cnn, y_pred_labels)
print(f"CNN Consistent Accuracy: {consistent_accuracy_cnn}")

# Plot confusion matrix with updated accuracy
cm_cnn = confusion_matrix(y_true_cnn, y_pred_labels)
plt.figure(figsize=(12, 12))
sns.heatmap(cm_cnn, annot=True, linewidths=.5, square=True, cmap='Greens_r', fmt='0.4g')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title_cnn = 'CNN Accuracy Score (Updated): {0}'.format(consistent_accuracy_cnn)
plt.title(all_sample_title_cnn)
plt.show()

print(y_test_int[:10])

y_test_int = np.argmax(y_test, axis=1)
print(y_test_int)

print(y_test_int.shape)

print(y_test_int.dtype)

y_test_int = np.argmax(y_test, axis=1)

y_test_int = np.argmax(y_test, axis=1)

y_test_OHE = to_categorical(y_test)

y_test_int = np.argmax(y_test_OHE, axis=1)

print("y_test_int shape:", y_test_int.shape)
print("y_test_int data type:", y_test_int.dtype)
print("predictions_cnn shape:", predictions_cnn.shape)
print("predictions_cnn data type:", predictions_cnn.dtype)

"""it's necessary that y_test_init and prediction_cnn have the same dimension  to avoid errors

"""

y_test_mono = np.argmax(y_test, axis=1)

print("y_test_int shape:", y_test_int.shape)
print("y_test_int data type:", y_test_int.dtype)
print("predictions_cnn shape:", predictions_cnn.shape)
print("predictions_cnn data type:", predictions_cnn.dtype)

from sklearn.metrics import classification_report

# Classification report
report = classification_report(y_test_mono, predictions_cnn)

# Classification report with the precision for each class
print(report)

from sklearn.metrics import classification_report

report = classification_report(y_test_mono, predictions_cnn, output_dict=True)

# Precision for each class
precisions_per_class = {str(cls): report[str(cls)]['precision'] for cls in range(10)}

# Print the precision for each class
for cls, precision in precisions_per_class.items():
    print(f'Classe {cls}: {precision}')

"""FINAL EVALUATION PLOT

The different accuracy and precision can be compared in the following plot
"""

import matplotlib.pyplot as plt

# Define the average precision data for each model and class
models = ['RidgeClassifier', 'LogisticRegression', 'DecisionTree', 'RandomForest', 'SVM', 'CNN (3 epochs)', 'CNN (10 epochs)', 'CNN (hyperparameter tuning)']
classes = list(range(10))  # 10 classes in the MNIST dataset

# Average precision for each class for each model
precision_data = {
    'RidgeClassifier': [0.9147496617050067, 0.8218331616889805, 0.8908227848101266, 0.8176470588235294, 0.8178137651821862, 0.875, 0.897841726618705, 0.8645418326693227, 0.8368, 0.8323353293413174],
    'LogisticRegression': [0.9688385269121813, 0.9545454545454546, 0.9176300578034682, 0.9064856711915535, 0.9213313161875946, 0.9008547008547009, 0.934593023255814, 0.9350132625994695, 0.8771186440677966, 0.8910891089108911],
    'DecisionTree': [0.9380403458213257, 0.9508599508599509, 0.8290366350067843, 0.8301610541727672, 0.8643815201192251, 0.8118811881188119, 0.8967065868263473, 0.9173441734417345, 0.8023426061493412, 0.8314447592067988],
    'RandomForest': [0.9858356940509915, 0.9914004914004914, 0.9529085872576177, 0.9588235294117647, 0.9756468797564688, 0.9732888146911519, 0.9793510324483776, 0.9722222222222222, 0.9709302325581395, 0.9442857142857143],
    'SVM': [0.9887165021156559, 0.9902439024390244, 0.9677871148459384, 0.9836552748885586, 0.9744360902255639, 0.978405315614618, 0.9837758112094396, 0.9788079470198675, 0.9768451519536903, 0.9725829725829725],
    'CNN (3 epochs)': [0.956820412168793, 0.9807860262008734, 0.9794721407624634, 0.987012987012987, 0.9775051124744376, 0.9799777530589544, 0.986228813559322, 0.9672447013487476, 0.9840933191940615, 0.9673267326732673],
    'CNN (10 epochs)': [0.9739217652958877, 0.9902998236331569, 0.9862475442043221, 0.9793713163064833, 0.9796541200406917, 0.985244040862656, 0.9720207253886011, 0.9824046920821115, 0.9743326488706365, 0.9751737835153923],
    'CNN (hyperparameter tuning)': [0.9866939611054247, 0.9858281665190434, 0.9768115942028985, 0.947119924457035, 0.9808274470232089, 0.9828962371721779, 0.9822732012513035, 0.9773622047244095, 0.9810126582278481, 0.9722497522299306]
}

# Calculate the average precision for each model
avg_precisions = {model: sum(precision_data[model]) / len(precision_data[model]) for model in models}

# Find the class with the highest and lowest precision for each model
best_classes = {model: classes[precision_data[model].index(max(precision_data[model]))] for model in models}
worst_classes = {model: classes[precision_data[model].index(min(precision_data[model]))] for model in models}

# Create the graph
plt.figure(figsize=(12, 8))

# Plot the average precisions for each model
plt.bar(models, avg_precisions.values(), color='skyblue')

# Annotations for the best and worst predicted classes for each model
for i, model in enumerate(models):
    plt.text(i, avg_precisions[model] + 0.01, f'Best: Class {best_classes[model]}', ha='center', va='bottom', fontsize=10, color='green')
    plt.text(i, avg_precisions[model] - 0.04, f'Worst: Class {worst_classes[model]}', ha='center', va='bottom', fontsize=10, color='red')

# Add labels and title
plt.xlabel('Model')
plt.ylabel('Average Precision')
plt.title('Best and Worst Predicted Classes for Each Model')

# Show the graph
plt.ylim(0.7, 1.0)  # Set the lower limit of the y-axis for better visualization
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""The plot represents the best and the worst class predicted by each model, on the base on the precision computed for each class for each model. The best predicted class is the 0 and 1, while An analysis of the trend of the worst predicted classes reveals a heterogeneity of classes. The heterogeneity in the worst predicted class among different models can be attributed to several factors, including the intrinsic complexity of the data: some classes may be inherently more challenging to distinguish due to visual similarity or variability among samples within a class. This complexity may vary across classes, leading to lower precision for those classes across all models.
Moreover certain models might excel in capturing specific data relationships compared to others. For instance, more complex models like neural networks may be able to capture intricate data relationships better than simpler models like linear classifiers.
We have to consider also the quantity of a class in the training and test set: if a class has limited representation in the training data or if the data is noisy or mislabeled, it can negatively impact the model's ability to accurately predict that class.

"""

import matplotlib.pyplot as plt
import numpy as np

# Model names
model_names = ['RidgeClassifier', 'LogisticRegression', 'LogisticRegression (5 folds)', 'LogisticRegression (10 folds)', 'DecisionTree', 'RandomForest', 'SVM', 'CNN (3 epochs)', 'CNN (10 epochs)', 'Tuned CNN']

# Accuracies
accuracies = [0.8552857142857143, 0.9218571428571428, 0.9134444444444444, 0.9153809523809524, 0.877, 0.9715714285714285, 0.9797142857142858, 0.9765, 0.98, 0.9884]

# Precisions
precisions = [0.8564470914216108, 0.9217672097568258, 0.9132053932621541, 0.9151700793409735, 0.8773066300744394, 0.9715954242125319, 0.9797153514281507, 0.9766299008530559, 0.980032238118118, 0.9884433654448465]

# Model index
x = np.arange(len(model_names))

# Width of the bars
width = 0.35

fig, ax = plt.subplots(figsize=(12, 8))
bars1 = ax.bar(x - width/2, accuracies, width, label='Accuracy', color='skyblue')
bars2 = ax.bar(x + width/2, precisions, width, label='Precision', color='orange')

# labels, title, and legend
ax.set_xlabel('Models')
ax.set_ylabel('Score')
ax.set_title('Comparison of Accuracy and Precision for Different Models')
ax.set_xticks(x)
ax.set_xticklabels(model_names, rotation=45, ha='right')
ax.legend()

# text labels for each bar
for bar in bars1:
    height = bar.get_height()
    ax.annotate(f'{height:.3f}',
                xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3),
                textcoords="offset points",
                ha='center', va='bottom', fontsize=8)

for bar in bars2:
    height = bar.get_height()
    ax.annotate(f'{height:.3f}',
                xy=(bar.get_x() + bar.get_width() / 2, height),
                xytext=(0, 3),
                textcoords="offset points",
                ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()

"""From the descending order of accuracies, we can deduce that the CNN (Tuned) model achieved the highest accuracy followed by CNN (10 epochs), CNN (3 epochs), SVM, RandomForest, LogisticRegression, DecisionTree, and finally RidgeClassifier.

Here are some deductions we can make from this order:

Deep Learning Models (CNN): CNN models have shown to be the most performing among those tested.

Model Tuning: The CNN model that underwent hyperparameter tuning outperformed both the CNN with 10 epochs and 3 epochs. This demonstrates the importance of parameter tuning in improving model performance.

SVM and RandomForest Models: They follow the CNN models in terms of accuracy but are still significantly better than linear regression models and simpler classification algorithms like DecisionTree and RidgeClassifier.

Linear Models (LogisticRegression and RidgeClassifier): They have lower performance compared to tree-based models and more complex machine learning algorithms, especially when dealing with complex problems like image classification.

In summary, we can deduce that for complex problems like image classification, Deep Learning models such as CNNs tend to achieve the best performance, especially when subjected to hyperparameter tuning. However, it's important to also consider the computational cost associated with training and tuning such models.
"""